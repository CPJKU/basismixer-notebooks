{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Predictive Models\n",
    "\n",
    "In the last two notebooks we had a look at two of the components of the Basis Mixer. In this notebook we add the third part of the puzzle: the **Predictive Models**.\n",
    "\n",
    "A predictive model is defined as a mathematical which maps score information (encoded by the basis functions) $\\mathbf{\\Phi}$ to expressive parameters $\\mathbf{Y}$\n",
    "\n",
    "$$F(\\boldsymbol{\\Phi}) = \\mathbf{Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Defining and Building Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "from basismixer import make_datasets\n",
    "from helper import init_dataset, data\n",
    "from helper.predictions import construct_model, setup_output_directory, train_model, split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = setup_output_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The configuration of the full predictive model can be defined as a list of models defined for individual (or groups) of expressive parameters.\n",
    "\n",
    "The structure of this configuration can be summarized as follows:\n",
    "\n",
    "* `input_type`: specifies if the model predicts *notewise* or *onsetwise* parameters.\n",
    "* `basis_functions`: A list with the basis functions (or the familiy of basis functions) used to specify the model. Alternatively, we can use a dataset to specify the basis functions.\n",
    "* `parameter_names`: Name of the expressive parameters\n",
    "* `model`: A dictionary specifying the architecture of the model\n",
    "    * `constructor`: A list specifying the module and method used to construct the model\n",
    "    * `args`: Arguments for the constructor.\n",
    "* `train_args`: A dictionary containing parameters for training the model.\n",
    "\n",
    "Let us define an example of such an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model_config = [\n",
    "    dict(onsetwise=False,\n",
    "         basis_functions=['polynomial_pitch_basis',\n",
    "                          'loudness_direction_basis',\n",
    "                          'tempo_direction_basis',\n",
    "                          'articulation_basis',\n",
    "                          'duration_basis',\n",
    "                          # my_basis,\n",
    "                          'slur_basis',\n",
    "                          'fermata_basis',\n",
    "                          'metrical_basis'],\n",
    "         parameter_names=['velocity_dev', 'timing', 'articulation_log'],\n",
    "         seq_len=1,\n",
    "         model=dict(constructor=['basismixer.predictive_models', 'FeedForwardModel'],\n",
    "                    args=dict(hidden_size=128)),\n",
    "         train_args=dict(\n",
    "             optimizer=['Adam', dict(lr=1e-4)],\n",
    "             epochs=1,\n",
    "             save_freq=1,\n",
    "             early_stopping=100,\n",
    "             batch_size=1000,\n",
    "         )\n",
    "    ),\n",
    "    dict(onsetwise=True,\n",
    "         basis_functions=['polynomial_pitch_basis',\n",
    "                          'loudness_direction_basis',\n",
    "                          'tempo_direction_basis',\n",
    "                          'articulation_basis',\n",
    "                          'duration_basis',\n",
    "                          'slur_basis',\n",
    "                          'fermata_basis',\n",
    "                          'metrical_basis'],\n",
    "         parameter_names=['velocity_trend', 'beat_period_standardized', 'beat_period_mean', 'beat_period_std'],\n",
    "         seq_len=200,\n",
    "         model=dict(constructor=['basismixer.predictive_models', 'RecurrentModel'],\n",
    "                    args=dict(recurrent_size=128,\n",
    "                              n_layers=1,\n",
    "                              hidden_size=64)),\n",
    "         train_args=dict(\n",
    "             optimizer=['Adam', dict(lr=1e-4)],\n",
    "             epochs=1,\n",
    "             save_freq=1,\n",
    "             early_stopping=100,\n",
    "             batch_size=20,\n",
    "         )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fd9aec80e840e6aadd666f10befa93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_dataset() # download the corpus if necessary; set some variables\n",
    "\n",
    "# path to the MusicXML and Match files\n",
    "xmlfolder = os.path.join(data.DATASET_DIR, 'musicxml')\n",
    "matchfolder = os.path.join(data.DATASET_DIR, 'match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Dropping slur 1 starting at 80 (n33-1) and ending at 80 (n36-1)\n",
      "[WARNING] Dropping slur 1 starting at 104 (n37a-1) and ending at 80 (n36-1)\n",
      "[WARNING] Dropping slur 1 starting at 272 (n33-2) and ending at 272 (n36-2)\n",
      "[WARNING] Dropping slur 1 starting at 296 (n37a-2) and ending at 272 (n36-2)\n",
      "[WARNING] Dropping slur 1 starting at 432 (n96-1) and ending at 432 (n98-1)\n",
      "[WARNING] Dropping slur 1 starting at 440 (n106-1) and ending at 432 (n98-1)\n",
      "[WARNING] Dropping slur 1 starting at 624 (n96-2) and ending at 624 (n98-2)\n",
      "[WARNING] Dropping slur 1 starting at 632 (n106-2) and ending at 624 (n98-2)\n",
      "[WARNING] Dropping slur 3 starting at 1632 (n120-1) and ending at 1632 (n122-1)\n",
      "[WARNING] Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "[WARNING] Dropping slur 3 starting at 2592 (n120-2) and ending at 2592 (n122-2)\n"
     ]
    }
   ],
   "source": [
    "datasets = make_datasets(model_config,\n",
    "                         xmlfolder,\n",
    "                         matchfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "## Training the models\n",
    "\n",
    "Given a training set of expressive performances aligned to their scores, we can train the models in a supervised way by minimizing the *mean squared error* between predictions and the observed expressive parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] No GPU available! Training will be performed on CPU.\n",
      "epoch: 0/1:  11%|█         | 3/28 [00:00<00:01, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pieces per dataset\n",
      "Train set:\t57\n",
      "Test set:\t17\n",
      "Validation set:\t14\n",
      "\n",
      "[79 62  5 47  4  0  7 58 50 70 26 24 31 33 63 85 81 23 40 29 67 55 76 78\n",
      " 12 75 48 86 20 37 43 59 34 52  6 60 71 80 84 44 49 11 54 39 69 14  1 83\n",
      "  9  2 21 46 10  8 38 72 25]\n",
      "[51 82  3 65 27 57 35 19 15 17 73 18 56 66]\n",
      "[74 77 16 53 28 87 42 32 45 41 68 30 61 22 13 36 64]\n",
      "27881 6808 8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/1: 100%|██████████| 28/28 [00:01<00:00, 19.86it/s]\n",
      "[WARNING] No GPU available! Training will be performed on CPU.\n",
      "epoch: 0/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pieces per dataset\n",
      "Train set:\t57\n",
      "Test set:\t17\n",
      "Validation set:\t14\n",
      "\n",
      "[21 42 23 15 39 44 49 82 81 60 62 16  6 58 61 32 74 84 54 70 41 86 50 53\n",
      " 64 46 13  9 48 67 27 34 77 45 57 17 19 29  4 36 25 28  7 47  1 87 55  3\n",
      " 71 56 51 30 43  8 68 65 66]\n",
      "[18 22 72 26 20 85 35 40 73 10 79 33 83 76]\n",
      "[63 80 78 69 31  2 38 11 37 24  0 14  5 12 75 52 59]\n",
      "18 0 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/1: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "/Users/aae/miniconda3/envs/basismixer/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/aae/miniconda3/envs/basismixer/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c46e86e380e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_out_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/basismixer-notebooks/helper/predictions.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_set, valid_set, config, out_dir)\u001b[0m\n\u001b[1;32m    148\u001b[0m                                 \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                                 **config['train_args'])\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repos/basismixer/basismixer/predictive_models/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_comparison\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'smaller'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mis_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_comparison\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'larger'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "models = []\n",
    "test_sets = []\n",
    "for (dataset, in_names, out_names), config in zip(datasets, model_config):\n",
    "    \n",
    "    # Build model\n",
    "    model, model_out_dir = construct_model(config, in_names, out_names, out_dir)\n",
    "    # Split datasets\n",
    "    train_set, valid_set, test_set = split_dataset(dataset)\n",
    "    # Train Model\n",
    "    train_model(model, train_set, valid_set, config, model_out_dir)\n",
    "    \n",
    "    models.append(model)\n",
    "    test_sets.append(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# plot_predictions(models, targets)\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "03_predictive_models.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
